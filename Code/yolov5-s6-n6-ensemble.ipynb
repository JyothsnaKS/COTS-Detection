{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install Libraries","metadata":{"papermill":{"duration":0.033246,"end_time":"2022-04-22T02:40:41.128819","exception":false,"start_time":"2022-04-22T02:40:41.095573","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# !pip install -qU bbox-utility\n# !pip download bbox-utility\n# !pip download ensemble-boxes","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":0.041853,"end_time":"2022-04-22T02:40:41.20223","exception":false,"start_time":"2022-04-22T02:40:41.160377","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:40:23.595631Z","iopub.execute_input":"2022-04-22T13:40:23.596279Z","iopub.status.idle":"2022-04-22T13:40:23.615009Z","shell.execute_reply.started":"2022-04-22T13:40:23.596182Z","shell.execute_reply":"2022-04-22T13:40:23.614082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --no-index --find-links '/kaggle/input/' '/kaggle/input/icevision-essentials/icevision-rCHSs/repos/loguru-0.6.0-py3-none-any.whl'\n!pip install --no-index --find-links '/kaggle/input/modules/' '/kaggle/input/modules/bbox_utility-1.0.13-py3-none-any.whl'\n!pip install --no-index --find-links '/kaggle/input/modules/' '/kaggle/input/modules/ensemble_boxes-1.0.9-py3-none-any.whl'","metadata":{"papermill":{"duration":32.573531,"end_time":"2022-04-22T02:41:13.807061","exception":false,"start_time":"2022-04-22T02:40:41.23353","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:40:23.672915Z","iopub.execute_input":"2022-04-22T13:40:23.673201Z","iopub.status.idle":"2022-04-22T13:40:51.126276Z","shell.execute_reply.started":"2022-04-22T13:40:23.67317Z","shell.execute_reply":"2022-04-22T13:40:51.12508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{"papermill":{"duration":0.037393,"end_time":"2022-04-22T02:41:13.880401","exception":false,"start_time":"2022-04-22T02:41:13.843008","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport glob\n\nimport shutil\nimport sys\nsys.path.append('../input/tensorflow-great-barrier-reef')\nsys.path.append('/kaggle/input/weightedboxesfusion/')\n\nfrom IPython.display import display\nfrom ensemble_boxes import *\nfrom PIL import Image\nimport torch","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.529984,"end_time":"2022-04-22T02:41:14.447647","exception":false,"start_time":"2022-04-22T02:41:13.917663","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:40:51.131112Z","iopub.execute_input":"2022-04-22T13:40:51.131399Z","iopub.status.idle":"2022-04-22T13:40:51.481057Z","shell.execute_reply.started":"2022-04-22T13:40:51.131364Z","shell.execute_reply":"2022-04-22T13:40:51.480372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR  = '/kaggle/input/tensorflow-great-barrier-reef/'","metadata":{"papermill":{"duration":0.044344,"end_time":"2022-04-22T02:41:15.683462","exception":false,"start_time":"2022-04-22T02:41:15.639118","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:40:52.784878Z","iopub.execute_input":"2022-04-22T13:40:52.785123Z","iopub.status.idle":"2022-04-22T13:40:52.791068Z","shell.execute_reply.started":"2022-04-22T13:40:52.785095Z","shell.execute_reply":"2022-04-22T13:40:52.789896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f'{ROOT_DIR}/train.csv')\ndf['old_image_path'] = f'{ROOT_DIR}/train_images/video_'+df.video_id.astype(str)+'/'+df.video_frame.astype(str)+'.jpg'\ndf['annotations'] = df['annotations'].progress_apply(eval)\ndisplay(df.head(2))","metadata":{"papermill":{"duration":0.562594,"end_time":"2022-04-22T02:41:18.052033","exception":false,"start_time":"2022-04-22T02:41:17.489439","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:40:54.311404Z","iopub.execute_input":"2022-04-22T13:40:54.312086Z","iopub.status.idle":"2022-04-22T13:40:54.829661Z","shell.execute_reply.started":"2022-04-22T13:40:54.312037Z","shell.execute_reply":"2022-04-22T13:40:54.828604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Number of BBoxes\n> Nearly 80% images are without any bbox.","metadata":{"papermill":{"duration":0.036732,"end_time":"2022-04-22T02:41:18.126151","exception":false,"start_time":"2022-04-22T02:41:18.089419","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df['num_bbox'] = df['annotations'].progress_apply(lambda x: len(x))\ndata = (df.num_bbox>0).value_counts(normalize=True)*100\nprint(f\"No BBox: {data[0]:0.2f}% | With BBox: {data[1]:0.2f}%\")","metadata":{"papermill":{"duration":0.155373,"end_time":"2022-04-22T02:41:18.31893","exception":false,"start_time":"2022-04-22T02:41:18.163557","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:40:54.831111Z","iopub.execute_input":"2022-04-22T13:40:54.831428Z","iopub.status.idle":"2022-04-22T13:40:54.942185Z","shell.execute_reply.started":"2022-04-22T13:40:54.831383Z","shell.execute_reply":"2022-04-22T13:40:54.941059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clean Data\n* In this notebook, we use only **bboxed-images** (`~5k`). We can use all `~23K` images for train but most of them don't have any labels. So it would be easier to carry out experiments using only **bboxed images**.","metadata":{"papermill":{"duration":0.038282,"end_time":"2022-04-22T02:41:18.396216","exception":false,"start_time":"2022-04-22T02:41:18.357934","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df = df.query(\"num_bbox>0\")","metadata":{"papermill":{"duration":0.064393,"end_time":"2022-04-22T02:41:18.499311","exception":false,"start_time":"2022-04-22T02:41:18.434918","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:40:54.943734Z","iopub.execute_input":"2022-04-22T13:40:54.944058Z","iopub.status.idle":"2022-04-22T13:40:54.968504Z","shell.execute_reply.started":"2022-04-22T13:40:54.944016Z","shell.execute_reply":"2022-04-22T13:40:54.967785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper","metadata":{"papermill":{"duration":0.038096,"end_time":"2022-04-22T02:41:18.575721","exception":false,"start_time":"2022-04-22T02:41:18.537625","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from bbox.utils import coco2yolo, coco2voc, voc2yolo\nfrom bbox.utils import draw_bboxes, load_image\nfrom bbox.utils import clip_bbox, str2annot, annot2str\n\ndef get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\n\nnp.random.seed(32)\ncolors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n          for idx in range(1)]","metadata":{"_kg_hide-input":false,"papermill":{"duration":0.990782,"end_time":"2022-04-22T02:41:19.604837","exception":false,"start_time":"2022-04-22T02:41:18.614055","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:40:54.970246Z","iopub.execute_input":"2022-04-22T13:40:54.970592Z","iopub.status.idle":"2022-04-22T13:40:55.88085Z","shell.execute_reply.started":"2022-04-22T13:40:54.97053Z","shell.execute_reply":"2022-04-22T13:40:55.879903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create BBox","metadata":{"papermill":{"duration":0.03788,"end_time":"2022-04-22T02:41:19.68037","exception":false,"start_time":"2022-04-22T02:41:19.64249","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df['bboxes'] = df.annotations.progress_apply(get_bbox)\ndf.head(2)","metadata":{"papermill":{"duration":0.116847,"end_time":"2022-04-22T02:41:19.835394","exception":false,"start_time":"2022-04-22T02:41:19.718547","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:40:55.884255Z","iopub.execute_input":"2022-04-22T13:40:55.884631Z","iopub.status.idle":"2022-04-22T13:40:56.102663Z","shell.execute_reply.started":"2022-04-22T13:40:55.884583Z","shell.execute_reply":"2022-04-22T13:40:56.102016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensembling","metadata":{"papermill":{"duration":0.039795,"end_time":"2022-04-22T02:41:20.095431","exception":false,"start_time":"2022-04-22T02:41:20.055636","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def voc2yolo(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    voc  => [x1, y1, x2, y2]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]/ image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]/ image_height\n    \n    w = bboxes[..., 2] - bboxes[..., 0]\n    h = bboxes[..., 3] - bboxes[..., 1]\n    \n    bboxes[..., 0] = bboxes[..., 0] + w/2\n    bboxes[..., 1] = bboxes[..., 1] + h/2\n    bboxes[..., 2] = w\n    bboxes[..., 3] = h\n    \n    return bboxes\n\ndef yolo2voc(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y2]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n    \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n    \n    return bboxes\n\ndef coco2yolo(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    coco => [xmin, ymin, w, h]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # normolizinig\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]/ image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]/ image_height\n    \n    # converstion (xmin, ymin) => (xmid, ymid)\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\ndef yolo2coco(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    coco => [xmin, ymin, w, h]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # denormalizing\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n    \n    # converstion (xmid, ymid) => (xmin, ymin) \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\ndef voc2coco(bboxes, image_height=720, image_width=1280):\n    bboxes  = voc2yolo(bboxes, image_height, image_width)\n    bboxes  = yolo2coco(bboxes, image_height, image_width)\n    return bboxes\n\ndef coco2voc(bboxes, image_height=720, image_width=1280):\n    bboxes  = coco2yolo(bboxes, image_height, image_width)\n    bboxes  = yolo2voc(bboxes, image_height, image_width)\n    return bboxes\n\ndef load_image(image_path):\n    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n\n\ndef plot_one_box(x, img, color=None, label=None, line_thickness=None,score=None):\n    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    label=label+\"{:.2f}%\".format(score)\n    if label:\n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n\ndef draw_bboxes(img, bboxes, classes, class_ids, colors = None, show_classes = None, bbox_format = 'yolo', class_name = False, line_thickness = 2,scores=None):  \n     \n    image = img.copy()\n    show_classes = classes if show_classes is None else show_classes\n    colors = (0, 255 ,0) if colors is None else colors\n    \n    if bbox_format == 'yolo':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            score   = scores[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes:\n            \n                x1 = round(float(bbox[0])*image.shape[1])\n                y1 = round(float(bbox[1])*image.shape[0])\n                w  = round(float(bbox[2])*image.shape[1]/2) #w/2 \n                h  = round(float(bbox[3])*image.shape[0]/2)\n\n                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(get_label(cls)),\n                             line_thickness = line_thickness,score=score)\n            \n    elif bbox_format == 'coco':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            score   = scores[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes:            \n                x1 = int(round(bbox[0]))\n                y1 = int(round(bbox[1]))\n                w  = int(round(bbox[2]))\n                h  = int(round(bbox[3]))\n\n                voc_bbox = (x1, y1, x1+w, y1+h)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(cls_id),\n                             line_thickness = line_thickness,score=score)\n\n    elif bbox_format == 'voc_pascal':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            score   = scores[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes: \n                x1 = int(round(bbox[0]))\n                y1 = int(round(bbox[1]))\n                x2 = int(round(bbox[2]))\n                y2 = int(round(bbox[3]))\n                voc_bbox = (x1, y1, x2, y2)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(cls_id),\n                             line_thickness = line_thickness,score=score)\n    else:\n        raise ValueError('wrong bbox format')\n\n    return image\n\ndef show_img(img, bboxes, bbox_format='yolo',scores=None):\n    names  = ['starfish']*len(bboxes)\n    labels = [0]*len(bboxes)\n    img    = draw_bboxes(img = img,\n                           bboxes = bboxes, \n                           classes = names,\n                           class_ids = labels,\n                           class_name = True, \n                           colors = colors, \n                           bbox_format = bbox_format,\n                           line_thickness = 2,scores=scores)\n    return Image.fromarray(img).resize((800, 400))\n\nnp.random.seed(32)\ncolors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n          for idx in range(1)]","metadata":{"papermill":{"duration":0.093036,"end_time":"2022-04-22T02:41:20.318623","exception":false,"start_time":"2022-04-22T02:41:20.225587","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:40:56.136179Z","iopub.execute_input":"2022-04-22T13:40:56.136663Z","iopub.status.idle":"2022-04-22T13:40:56.186859Z","shell.execute_reply.started":"2022-04-22T13:40:56.136627Z","shell.execute_reply":"2022-04-22T13:40:56.185767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model(ckpt_path):\n    model = torch.hub.load('/kaggle/input/yolov5-lib-ds/','custom',path=ckpt_path, source='local',force_reload=True)\n    model.conf = 0.25 #0.1  \n    model.iou  = 0.4 #0.2 \n    model.classes = None   \n    model.multi_label = False \n    model.max_det = 1000  \n    return model\n\ndef get_prediction(model, img):\n    results = model(img, size=3000, augment=True)\n    preds   = results.pandas().xyxy[0]\n    bboxes  = preds[['xmin','ymin','xmax','ymax']].values\n    print(bboxes)\n    if len(bboxes) > 0:\n        return bboxes, preds['confidence'].values\n    return [], []\n\ndef wbf(bboxes, confs):\n    boxes =  [bbox/1280 for bbox in bboxes]\n    scores = [conf for conf in confs]\n    labels = [np.ones(conf.shape[0]) for conf in confs]\n    \n    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=[1,1], iou_thr=0.2, skip_box_thr=0.001)\n    \n    boxes = boxes*(1280-1)\n    return boxes, scores, labels","metadata":{"papermill":{"duration":0.052007,"end_time":"2022-04-22T02:41:20.410161","exception":false,"start_time":"2022-04-22T02:41:20.358154","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:51:23.136872Z","iopub.execute_input":"2022-04-22T13:51:23.137208Z","iopub.status.idle":"2022-04-22T13:51:23.148528Z","shell.execute_reply.started":"2022-04-22T13:51:23.137175Z","shell.execute_reply":"2022-04-22T13:51:23.147373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /root/.config/Ultralytics\n!cp /kaggle/input/yolov5-font/Arial.ttf /root/.config/Ultralytics/Arial.ttf","metadata":{"papermill":{"duration":0.808778,"end_time":"2022-04-22T02:41:21.258425","exception":false,"start_time":"2022-04-22T02:41:20.449647","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:40:56.974332Z","iopub.execute_input":"2022-04-22T13:40:56.975305Z","iopub.status.idle":"2022-04-22T13:40:57.763151Z","shell.execute_reply.started":"2022-04-22T13:40:56.975245Z","shell.execute_reply":"2022-04-22T13:40:57.7617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m1 = load_model('/kaggle/input/yolowts/best.pt')\nm2 = load_model('/kaggle/input/yolowts/best-2.pt') ","metadata":{"papermill":{"duration":21.591476,"end_time":"2022-04-22T02:41:42.891349","exception":true,"start_time":"2022-04-22T02:41:21.299873","status":"failed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:40:57.764929Z","iopub.execute_input":"2022-04-22T13:40:57.765179Z","iopub.status.idle":"2022-04-22T13:41:00.388696Z","shell.execute_reply.started":"2022-04-22T13:40:57.765151Z","shell.execute_reply":"2022-04-22T13:41:00.387806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths = df[df.num_bbox>1].old_image_path.tolist()","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:41:00.390821Z","iopub.execute_input":"2022-04-22T13:41:00.391183Z","iopub.status.idle":"2022-04-22T13:41:00.402071Z","shell.execute_reply.started":"2022-04-22T13:41:00.391139Z","shell.execute_reply":"2022-04-22T13:41:00.401472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization of WBF Ensembling Prediction","metadata":{}},{"cell_type":"code","source":"# for p in paths:\n#     img = cv2.imread(p)[...,::-1]\n#     b1, c1 = get_prediction(m1, img)\n#     b2, c2 = get_prediction(m2, img)\n#     if len(b1) > 0:\n#         b1 = np.array(b1)\n#     if len(b2) > 0:\n#         b2 = np.array(b2)\n    \n#     # voc  => [x1, y1, x2, y2]\n#     # coco => [xmin, ymin, w, h]\n#     # model predictions are in voc format\n#     # for testing we need predictions in coco format\n#     if len(b1) > 0 and len(b2) > 0:\n#         b, c, labels = wbf([b1, b2], [c1, c2])\n#         b = voc2coco(b).astype(int)\n#     elif len(b1) > 0:\n#         b, c = voc2coco(b1, image_height=720, image_width=1280), c1\n#     elif len(b2) > 0:\n#         b, c = voc2coco(b2, image_height=720, image_width=1280), c2\n#     else:\n#         b, c = [], []\n#     print(b1, c1, b2, c2, b, c)\n#     print(b, c)\n#     if True: #len(b1) > 0 and len(b2) > 0:\n#         print('\\n\\nYOLOV5s6 Predictions ')\n#         if len(b1) > 0:            \n#             display(show_img(img, b1, bbox_format='voc_pascal',scores=c1))\n#         else:        \n#             display(show_img(img, [], bbox_format='voc_pascal',scores=c1))\n\n#         print('\\n\\nYoloV5n6 Predictions ')  \n#         if len(b2) > 0:\n#             display(show_img(img, b2, bbox_format='voc_pascal',scores=c2))\n#         else:\n#             display(show_img(img, [], bbox_format='voc_pascal',scores=c2))\n\n#         print('\\n\\nEnsemble (WBF) Predictions ')\n#         if len(b) > 0: \n#             display(show_img(img, b, bbox_format='coco',scores=c))\n#         else:\n#             display(show_img(img, [], bbox_format='coco',scores=None))\n    ","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:53:35.107243Z","iopub.execute_input":"2022-04-22T13:53:35.10761Z","iopub.status.idle":"2022-04-22T13:53:35.112651Z","shell.execute_reply.started":"2022-04-22T13:53:35.10755Z","shell.execute_reply":"2022-04-22T13:53:35.111798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:51:51.572187Z","iopub.execute_input":"2022-04-22T13:51:51.572485Z","iopub.status.idle":"2022-04-22T13:51:51.578824Z","shell.execute_reply.started":"2022-04-22T13:51:51.572451Z","shell.execute_reply":"2022-04-22T13:51:51.577873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import greatbarrierreef\nenv = greatbarrierreef.make_env()\niter_test = env.iter_test()  ","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:51:53.73751Z","iopub.execute_input":"2022-04-22T13:51:53.73784Z","iopub.status.idle":"2022-04-22T13:51:53.810338Z","shell.execute_reply.started":"2022-04-22T13:51:53.737805Z","shell.execute_reply":"2022-04-22T13:51:53.809538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (pixel_array, sample_prediction_df) in iter_test:\n    img = pixel_array\n    b1, c1 = get_prediction(m1, img)\n    b2, c2 = get_prediction(m2, img)\n    \n    if len(b1) > 0:\n        b1 = np.array(b1)\n    if len(b2) > 0:\n        b2 = np.array(b2)\n    \n    if len(b1) > 0 and len(b2) > 0:\n        b, c, labels = wbf([b1, b2], [c1, c2])\n        b = voc2coco(b).astype(int)\n    elif len(b1) > 0:\n        b, c = voc2coco(b1, image_height=720, image_width=1280), c1\n    elif len(b2) > 0:\n        b, c = voc2coco(b2, image_height=720, image_width=1280), c2\n    else:\n        b = []\n    \n    \n    predictions = list()\n    for i in range(len(b)):\n        box = b[i]        \n        score = c[i]\n        if score > 0.1:\n            x_min = int(box[0])\n            y_min = int(box[1])\n            bbox_width = int(box[2])\n            bbox_height = int(box[3])\n            predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n#         s = str(c[i]) + ' ' + str(b[i][0]) + ' ' + str(b[i][1]) + ' ' +  str(b[i][2]) + ' ' +  str(b[i][3])\n#         predictions.append(s)\n\n#     print(predictions)\n    sample_prediction_df['annotations'] = ' '.join(predictions)\n    env.predict(sample_prediction_df)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-04-22T13:52:01.822027Z","iopub.execute_input":"2022-04-22T13:52:01.823047Z","iopub.status.idle":"2022-04-22T13:52:28.898534Z","shell.execute_reply.started":"2022-04-22T13:52:01.823001Z","shell.execute_reply":"2022-04-22T13:52:28.897594Z"},"trusted":true},"execution_count":null,"outputs":[]}]}